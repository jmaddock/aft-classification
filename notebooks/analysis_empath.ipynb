{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trying-integration",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "* Table containing accuracy, precision, specificity, recall, f1, roc-auc for best classifier configurations\n",
    "* Roc-auc graphs for each best classifier configuration\n",
    "* Table of accuracy, precision, specificity, and percent uncertainty at each threshold\n",
    "* Graphs of accuracy, precision, specificity, and percent uncertainty at each threshold\n",
    "* Some kind of graph/table using empath (top categories at each threshold?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "resistant-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import importlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_score, recall_score, f1_score, average_precision_score, roc_auc_score, roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "from empath import Empath\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "blocked-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biological-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BINARY_PATH = '../models/best_models_w2v_rating_2021-05-29.pickle'\n",
    "\n",
    "with open(MODEL_BINARY_PATH, 'rb') as filestream:\n",
    "    d = pickle.load(filestream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "northern-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BINARY_PATH = '../models/best_models_w2v_rating_SVC_2021-06-03.pickle'\n",
    "\n",
    "with open(MODEL_BINARY_PATH, 'rb') as filestream:\n",
    "    d_svc = pickle.load(filestream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "central-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "    'accuracy':accuracy_score,\n",
    "    'precision':partial(precision_score),\n",
    "    'negative predictive value':partial(precision_score,pos_label = -1),\n",
    "    'recall':recall_score,\n",
    "    'f1':f1_score,\n",
    "    #'average_precision':average_precision_score,\n",
    "    'roc_auc':roc_auc_score\n",
    "}\n",
    "\n",
    "def generate_sample(df,n,balance=True):\n",
    "    if balance and n:\n",
    "        pos = df.loc[df['aft_net_sign_helpful'] > 0].sample(int(n/2))\n",
    "        neg = df.loc[df['aft_net_sign_helpful'] < 0].sample(int(n/2))\n",
    "        sample = pos.append(neg)\n",
    "    elif n:\n",
    "        sample = df.loc[df['aft_net_sign_helpful'] != 0].sample(n)\n",
    "    else:\n",
    "        sample = df.loc[df['aft_net_sign_helpful'] != 0]\n",
    "    return sample\n",
    "\n",
    "def proba_to_preds(probability_list,threshold=.5):\n",
    "    preds = []\n",
    "    for proba in probability_list:\n",
    "        if proba[1] > threshold:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(-1)\n",
    "    return preds\n",
    "\n",
    "def results_to_table(proba,truth):\n",
    "    result_dict = results_to_json(proba,truth)\n",
    "    return pd.DataFrame([result_dict])\n",
    "    #return results\n",
    "\n",
    "def results_to_json(proba,truth):\n",
    "    preds = proba_to_preds(proba)\n",
    "    results_dict = {}\n",
    "    for metric in METRICS:\n",
    "        if metric == 'roc_auc':\n",
    "            results_dict[metric] = METRICS[metric](truth,proba[:, 1])\n",
    "        else:\n",
    "            results_dict[metric] = METRICS[metric](truth,preds)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "basic-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path_w2v = '../datasets/vectorized/vectorized_w2v_rating_2021-03-31.json'\n",
    "\n",
    "def load_dataset(feature_path,sparse_matrix_path=None):\n",
    "    with open(feature_path,'r') as filestream:\n",
    "        df = pd.DataFrame(json.load(filestream))\n",
    "\n",
    "    df = generate_sample(df, None)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    if sparse_matrix_path:\n",
    "        with open(sparse_matrix_path,'rb') as filestream:\n",
    "            features = load_npz(filestream)\n",
    "            \n",
    "    else:\n",
    "        features = pd.DataFrame(df['feature_vector'].values.tolist()).to_numpy()\n",
    "\n",
    "    labels = df['aft_net_sign_helpful'].to_numpy()\n",
    "    \n",
    "    return features, labels, df\n",
    "\n",
    "features, labels, df = load_dataset(feature_path_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metallic-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = labels[d['indices']['train']]\n",
    "labels_test = labels[d['indices']['test']]\n",
    "features_train = features[d['indices']['train']]\n",
    "features_test = features[d['indices']['test']]\n",
    "df_test = df.iloc[d['indices']['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorporate-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "del d['classifiers']['SVC']\n",
    "\n",
    "for c in d_svc['classifiers']:\n",
    "    d['classifiers'][c] = d_svc['classifiers'][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "emotional-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifiers': {'GradientBoostingClassifier': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "               param_grid=[{'clf': [GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                               max_depth=7,\n",
       "                                                               max_features='log2',\n",
       "                                                               min_samples_leaf=13,\n",
       "                                                               n_estimators=700)],\n",
       "                            'clf__learning_rate': [0.01, 0.1, 0.5, 1],\n",
       "                            'clf__max_depth': [1, 3, 5, 7],\n",
       "                            'clf__max_features': ['log2'],\n",
       "                            'clf__min_samples_leaf': [1, 3, 5, 7, 13],\n",
       "                            'clf__n_estimators': [100, 300, 500, 700]}],\n",
       "               pre_dispatch=64, refit='roc_auc',\n",
       "               scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision')),\n",
       "  'LogisticRegression': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "               param_grid=[{'clf': [LogisticRegression(C=0.1)],\n",
       "                            'clf__C': [0.1, 1, 10], 'clf__penalty': ['l2']}],\n",
       "               pre_dispatch=64, refit='roc_auc',\n",
       "               scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision')),\n",
       "  'RandomForestClassifier': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "               param_grid=[{'clf': [RandomForestClassifier(max_features='log2',\n",
       "                                                           min_samples_leaf=13,\n",
       "                                                           n_estimators=640)],\n",
       "                            'clf__criterion': ['gini', 'entropy'],\n",
       "                            'clf__max_features': ['log2'],\n",
       "                            'clf__min_samples_leaf': [1, 3, 5, 7, 13],\n",
       "                            'clf__n_estimators': [10, 20, 40, 80, 160, 320,\n",
       "                                                  640]}],\n",
       "               pre_dispatch=64, refit='roc_auc',\n",
       "               scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision')),\n",
       "  'SVC_rbf': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "               param_grid=[{'clf': [SVC(C=10, cache_size=1000, gamma=0.001,\n",
       "                                        probability=True)],\n",
       "                            'clf__C': [0.1, 1, 10], 'clf__cache_size': [1000],\n",
       "                            'clf__gamma': [0.0, 0.001, 0.0001],\n",
       "                            'clf__kernel': ['rbf'], 'clf__probability': [True]}],\n",
       "               pre_dispatch=64, refit='roc_auc',\n",
       "               scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision')),\n",
       "  'SVC_linear': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "               param_grid=[{'clf': [SVC(C=0.1, cache_size=1000, kernel='linear',\n",
       "                                        probability=True)],\n",
       "                            'clf__C': [0.1, 1, 10], 'clf__cache_size': [1000],\n",
       "                            'clf__kernel': ['linear'],\n",
       "                            'clf__probability': [True]}],\n",
       "               pre_dispatch=64, refit='roc_auc',\n",
       "               scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision'))},\n",
       " 'indices': {'train': array([34176,  6367, 27522, ..., 65280, 47928, 15272]),\n",
       "  'test': array([ 56451,  70279,  70237, ...,  89983,  41387, 103801])}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "based-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = {}\n",
    "\n",
    "for model in d['classifiers']:\n",
    "    probas[model] = d['classifiers'][model].predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "heavy-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'help': 0.0,\n",
       " 'office': 0.0,\n",
       " 'dance': 0.0,\n",
       " 'money': 0.0,\n",
       " 'wedding': 0.0,\n",
       " 'domestic_work': 0.0,\n",
       " 'sleep': 0.0,\n",
       " 'medical_emergency': 0.0,\n",
       " 'cold': 0.0,\n",
       " 'hate': 0.0,\n",
       " 'cheerfulness': 0.0,\n",
       " 'aggression': 0.0,\n",
       " 'occupation': 0.0,\n",
       " 'envy': 0.0,\n",
       " 'anticipation': 0.0,\n",
       " 'family': 0.0,\n",
       " 'vacation': 0.0,\n",
       " 'crime': 0.0,\n",
       " 'attractive': 0.0,\n",
       " 'masculine': 0.0,\n",
       " 'prison': 0.0,\n",
       " 'health': 0.0,\n",
       " 'pride': 0.0,\n",
       " 'dispute': 0.0,\n",
       " 'nervousness': 0.0,\n",
       " 'government': 0.0,\n",
       " 'weakness': 0.0,\n",
       " 'horror': 0.0,\n",
       " 'swearing_terms': 0.0,\n",
       " 'leisure': 0.0,\n",
       " 'suffering': 0.0,\n",
       " 'royalty': 0.0,\n",
       " 'wealthy': 0.0,\n",
       " 'tourism': 0.0,\n",
       " 'furniture': 0.0,\n",
       " 'school': 0.0,\n",
       " 'magic': 0.0,\n",
       " 'beach': 0.0,\n",
       " 'journalism': 0.0,\n",
       " 'morning': 0.0,\n",
       " 'banking': 0.0,\n",
       " 'social_media': 0.0,\n",
       " 'exercise': 0.0,\n",
       " 'night': 0.0,\n",
       " 'kill': 0.0,\n",
       " 'blue_collar_job': 0.0,\n",
       " 'art': 0.0,\n",
       " 'ridicule': 0.0,\n",
       " 'play': 0.0,\n",
       " 'computer': 0.0,\n",
       " 'college': 0.0,\n",
       " 'optimism': 0.0,\n",
       " 'stealing': 0.0,\n",
       " 'real_estate': 0.0,\n",
       " 'home': 0.0,\n",
       " 'divine': 0.0,\n",
       " 'sexual': 0.0,\n",
       " 'fear': 0.0,\n",
       " 'irritability': 0.0,\n",
       " 'superhero': 0.0,\n",
       " 'business': 0.0,\n",
       " 'driving': 0.0,\n",
       " 'pet': 0.0,\n",
       " 'childish': 0.0,\n",
       " 'cooking': 0.0,\n",
       " 'exasperation': 0.0,\n",
       " 'religion': 0.0,\n",
       " 'hipster': 0.0,\n",
       " 'internet': 0.0,\n",
       " 'surprise': 0.0,\n",
       " 'reading': 0.0,\n",
       " 'worship': 0.0,\n",
       " 'leader': 0.0,\n",
       " 'independence': 0.0,\n",
       " 'movement': 0.2,\n",
       " 'body': 0.0,\n",
       " 'noise': 0.0,\n",
       " 'eating': 0.0,\n",
       " 'medieval': 0.0,\n",
       " 'zest': 0.0,\n",
       " 'confusion': 0.0,\n",
       " 'water': 0.0,\n",
       " 'sports': 0.0,\n",
       " 'death': 0.0,\n",
       " 'healing': 0.0,\n",
       " 'legend': 0.0,\n",
       " 'heroic': 0.0,\n",
       " 'celebration': 0.0,\n",
       " 'restaurant': 0.0,\n",
       " 'violence': 0.2,\n",
       " 'programming': 0.0,\n",
       " 'dominant_heirarchical': 0.0,\n",
       " 'military': 0.0,\n",
       " 'neglect': 0.0,\n",
       " 'swimming': 0.0,\n",
       " 'exotic': 0.0,\n",
       " 'love': 0.0,\n",
       " 'hiking': 0.0,\n",
       " 'communication': 0.0,\n",
       " 'hearing': 0.0,\n",
       " 'order': 0.0,\n",
       " 'sympathy': 0.0,\n",
       " 'hygiene': 0.0,\n",
       " 'weather': 0.0,\n",
       " 'anonymity': 0.0,\n",
       " 'trust': 0.0,\n",
       " 'ancient': 0.0,\n",
       " 'deception': 0.0,\n",
       " 'fabric': 0.0,\n",
       " 'air_travel': 0.0,\n",
       " 'fight': 0.0,\n",
       " 'dominant_personality': 0.0,\n",
       " 'music': 0.0,\n",
       " 'vehicle': 0.0,\n",
       " 'politeness': 0.0,\n",
       " 'toy': 0.0,\n",
       " 'farming': 0.0,\n",
       " 'meeting': 0.0,\n",
       " 'war': 0.0,\n",
       " 'speaking': 0.0,\n",
       " 'listen': 0.0,\n",
       " 'urban': 0.0,\n",
       " 'shopping': 0.0,\n",
       " 'disgust': 0.0,\n",
       " 'fire': 0.0,\n",
       " 'tool': 0.0,\n",
       " 'phone': 0.0,\n",
       " 'gain': 0.0,\n",
       " 'sound': 0.0,\n",
       " 'injury': 0.0,\n",
       " 'sailing': 0.0,\n",
       " 'rage': 0.0,\n",
       " 'science': 0.0,\n",
       " 'work': 0.0,\n",
       " 'appearance': 0.0,\n",
       " 'valuable': 0.0,\n",
       " 'warmth': 0.0,\n",
       " 'youth': 0.0,\n",
       " 'sadness': 0.0,\n",
       " 'fun': 0.0,\n",
       " 'emotional': 0.0,\n",
       " 'joy': 0.0,\n",
       " 'affection': 0.0,\n",
       " 'traveling': 0.0,\n",
       " 'fashion': 0.0,\n",
       " 'ugliness': 0.0,\n",
       " 'lust': 0.0,\n",
       " 'shame': 0.0,\n",
       " 'torment': 0.0,\n",
       " 'economics': 0.0,\n",
       " 'anger': 0.0,\n",
       " 'politics': 0.0,\n",
       " 'ship': 0.0,\n",
       " 'clothing': 0.0,\n",
       " 'car': 0.0,\n",
       " 'strength': 0.0,\n",
       " 'technology': 0.0,\n",
       " 'breaking': 0.0,\n",
       " 'shape_and_size': 0.0,\n",
       " 'power': 0.0,\n",
       " 'white_collar_job': 0.0,\n",
       " 'animal': 0.0,\n",
       " 'party': 0.0,\n",
       " 'terrorism': 0.0,\n",
       " 'smell': 0.0,\n",
       " 'disappointment': 0.0,\n",
       " 'poor': 0.0,\n",
       " 'plant': 0.0,\n",
       " 'pain': 0.2,\n",
       " 'beauty': 0.0,\n",
       " 'timidity': 0.0,\n",
       " 'philosophy': 0.0,\n",
       " 'negotiate': 0.0,\n",
       " 'negative_emotion': 0.2,\n",
       " 'cleaning': 0.0,\n",
       " 'messaging': 0.0,\n",
       " 'competing': 0.0,\n",
       " 'law': 0.0,\n",
       " 'friends': 0.0,\n",
       " 'payment': 0.0,\n",
       " 'achievement': 0.0,\n",
       " 'alcohol': 0.0,\n",
       " 'liquid': 0.0,\n",
       " 'feminine': 0.0,\n",
       " 'weapon': 0.0,\n",
       " 'children': 0.0,\n",
       " 'monster': 0.0,\n",
       " 'ocean': 0.0,\n",
       " 'giving': 0.0,\n",
       " 'contentment': 0.0,\n",
       " 'writing': 0.0,\n",
       " 'rural': 0.0,\n",
       " 'positive_emotion': 0.0,\n",
       " 'musical': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = Empath()\n",
    "lexicon.analyze(\"he hit the other person\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "automated-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empath_categories_diff(proba, labels, text, threshold=.5, step=.1, n_categories=5):\n",
    "    df = pd.DataFrame({\n",
    "        'proba_neg':proba.T[0],\n",
    "        'proba_pos':proba.T[1],\n",
    "        'labels':labels,\n",
    "        'text':text\n",
    "    })\n",
    "    df = df.loc[((df['proba_pos'] > threshold) & (df['proba_pos'] < (threshold+step))) | ((df['proba_neg'] > threshold) & (df['proba_neg'] < (threshold+step)))]\n",
    "    confusion = {}\n",
    "    confusion['tp'] = df.loc[(df['proba_pos'] > df['proba_neg']) & (df['labels'] == 1)]\n",
    "    confusion['tn'] = df.loc[(df['proba_pos'] < df['proba_neg']) & (df['labels'] == -1)]\n",
    "    confusion['fp'] = df.loc[(df['proba_pos'] > df['proba_neg']) & (df['labels'] == -1)]\n",
    "    confusion['fn'] = df.loc[(df['proba_pos'] < df['proba_neg']) & (df['labels'] == 1)]\n",
    "    cat_dict = {}\n",
    "    for cell in confusion:\n",
    "        text = ' '.join(confusion[cell]['text'].values)\n",
    "        categories = lexicon.analyze(text, normalize=True)\n",
    "        if categories:\n",
    "            cat_dict[cell] = ' '.join(list({k: v for k, v in sorted(categories.items(), key=lambda item: item[1], reverse=True)})[:n_categories])\n",
    "        else:\n",
    "            cat_dict[cell] = None\n",
    "        \n",
    "    return cat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-influence",
   "metadata": {},
   "source": [
    "## Topic Analysis\n",
    "\n",
    "In order to better understand classifier performance, investigate the topical makeup of both correct and incorrect classifications.  Using a dictionary based approach, we generate the top 5 topics at each probability threshold for all four quandrants of the confusion matrix: true positives, true negatives, false positives, and false negatives.  We use the Python Empath to generate categories at each threshold level.\n",
    "\n",
    "By comparing topics across these 4 quandrants we can determine whether misclassifications systematically effect certain topics, or whether these errors are relatively evenly distributed.  Systematically misclassifying specific types of feedback could introduce more bias, which would ultimately negate the end goal of this project.  Conversely, understanding what types of content are being correctly classified may help us understand where the classifier excels.\n",
    "\n",
    "Overall, we observe relatively high overlap between topics across thresholds and quandrants of the confusion matrix.  Of the 20 potential cells in the confusion-topic matrix (Table X), 'internet' occures 14 times, 'communication' occures 13 times, 'writing' occures 10 times, and 'reading' occures 9 times.  Noteably, none of these top topics appear for negative predictions when our confidence threshold is set to .9, or positive predictions when our confidence threshold is set to .8 (recall that our classifier does not make any positive predictions with above .9 confidence).  This likely indicates that these common topics are too general to help our classifier make a confident prediction.\n",
    "\n",
    "Some topics appear consistantly in either positive or negative predictions.  Journalism appears at the .5 through .7 confidence thresholds for both true and false positive predictions, but in none of our negative predictions.  Similarily, negative emotion appears at all thresholds for true negatives, at the .7 and .8 thresholds for false negatives, and in none of the positive predictions.  These common topics may be strong predictors of either positive or negative feedback, but their appearance in both the true and false rows of the confusion matrix indicates the highly contextual nature of the concept of helpfulness when applied to reader feedback.  For instance, while negative emotion appears in most unhelpful feedback, it also appears in some helpful feedback that our model misclassifies as unhelpful.  Similarily, while the topic journalism appears in most helpful feedback, our model tends to misclassify unhelpful feedback that falls under the category journalism.\n",
    "\n",
    "Noteably, the predictions about which our classifier is most confident also have the higher number of unique topics.  This could be because these topics are strong predictors of hepful or unhelpful feedback and therefore result in high confidence prediction, or simply it could result from a low number of predictions which produces a somewhat random distribution of topics.  For instance, 'domestic_work' and 'family' appear for both true negatives and false negatives, but only at the .9 confidence theshold.  Family, home, and shopping appear only for true negatives at the .9 confidence threshold, and 'sexual', 'swearing_terms', and 'ridicule' appear only for false negatives at the .9 confidence threshold.  'Help', 'office', 'dance', and 'money' all appear only for true and false positives at the .8 confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "powered-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all Counter({'internet': 14, 'communication': 13, 'writing': 10, 'reading': 9, 'negative_emotion': 7, 'journalism': 6, 'messaging': 3, 'phone': 3, 'speaking': 2, 'computer': 2, 'help': 2, 'office': 2, 'dance': 2, 'money': 2, 'domestic_work': 2, 'family': 2, 'business': 1, 'hate': 1, 'wedding': 1, 'social_media': 1, 'home': 1, 'shopping': 1, 'sexual': 1, 'swearing_terms': 1, 'ridicule': 1})\n",
      "tp Counter({'internet': 3, 'communication': 3, 'writing': 3, 'journalism': 3, 'reading': 3, 'speaking': 1, 'help': 1, 'office': 1, 'dance': 1, 'money': 1})\n",
      "tn Counter({'negative_emotion': 5, 'communication': 4, 'internet': 4, 'writing': 2, 'messaging': 2, 'phone': 2, 'reading': 1, 'hate': 1, 'domestic_work': 1, 'family': 1, 'home': 1, 'shopping': 1})\n",
      "fp Counter({'internet': 3, 'communication': 3, 'writing': 3, 'journalism': 3, 'reading': 3, 'help': 1, 'office': 1, 'dance': 1, 'money': 1, 'wedding': 1})\n",
      "fn Counter({'internet': 4, 'communication': 3, 'writing': 2, 'reading': 2, 'negative_emotion': 2, 'computer': 2, 'speaking': 1, 'business': 1, 'messaging': 1, 'phone': 1, 'social_media': 1, 'sexual': 1, 'domestic_work': 1, 'family': 1, 'swearing_terms': 1, 'ridicule': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>communication internet writing reading negative_emotion</td>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>communication internet writing reading speaking</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>internet communication negative_emotion writing messaging</td>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>internet communication writing reading business</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>negative_emotion internet communication messaging phone</td>\n",
       "      <td>communication internet writing reading journalism</td>\n",
       "      <td>internet communication negative_emotion computer messaging</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speaking help office dance money</td>\n",
       "      <td>negative_emotion internet hate communication phone</td>\n",
       "      <td>help office dance money wedding</td>\n",
       "      <td>internet negative_emotion phone social_media computer</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>negative_emotion domestic_work family home shopping</td>\n",
       "      <td>None</td>\n",
       "      <td>sexual domestic_work family swearing_terms ridicule</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tp  \\\n",
       "0  internet communication writing journalism reading   \n",
       "0  internet communication writing journalism reading   \n",
       "0  internet communication writing journalism reading   \n",
       "0                   speaking help office dance money   \n",
       "0                                               None   \n",
       "\n",
       "                                                          tn  \\\n",
       "0    communication internet writing reading negative_emotion   \n",
       "0  internet communication negative_emotion writing messaging   \n",
       "0    negative_emotion internet communication messaging phone   \n",
       "0         negative_emotion internet hate communication phone   \n",
       "0        negative_emotion domestic_work family home shopping   \n",
       "\n",
       "                                                  fp  \\\n",
       "0  internet communication writing journalism reading   \n",
       "0  internet communication writing journalism reading   \n",
       "0  communication internet writing reading journalism   \n",
       "0                    help office dance money wedding   \n",
       "0                                               None   \n",
       "\n",
       "                                                           fn threshold  \n",
       "0             communication internet writing reading speaking       0.5  \n",
       "0             internet communication writing reading business       0.6  \n",
       "0  internet communication negative_emotion computer messaging       0.7  \n",
       "0       internet negative_emotion phone social_media computer       0.8  \n",
       "0         sexual domestic_work family swearing_terms ridicule       0.9  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_uncertain_predictions(proba, labels, text, threshold=.5):\n",
    "    df = pd.DataFrame({\n",
    "        'proba_neg':proba.T[0],\n",
    "        'proba_pos':proba.T[1],\n",
    "        'labels':labels,\n",
    "        'text':text\n",
    "    })\n",
    "    df = df.loc[(df['proba_pos'] > threshold) | ((df['proba_neg'] > threshold))]\n",
    "    return df\n",
    "\n",
    "def get_empath_categories(proba, labels, text, threshold=.5, step=.1, n_categories=5):\n",
    "    df = remove_uncertain_predictions(\n",
    "        proba,\n",
    "        labels,\n",
    "        text,\n",
    "        threshold\n",
    "    )\n",
    "    confusion = {}\n",
    "    confusion['tp'] = df.loc[(df['proba_pos'] > df['proba_neg']) & (df['labels'] == 1)]\n",
    "    confusion['tn'] = df.loc[(df['proba_pos'] < df['proba_neg']) & (df['labels'] == -1)]\n",
    "    confusion['fp'] = df.loc[(df['proba_pos'] > df['proba_neg']) & (df['labels'] == -1)]\n",
    "    confusion['fn'] = df.loc[(df['proba_pos'] < df['proba_neg']) & (df['labels'] == 1)]\n",
    "    cat_dict = {}\n",
    "    for cell in confusion:\n",
    "        text = ' '.join(confusion[cell]['text'].values)\n",
    "        categories = lexicon.analyze(text, normalize=True)\n",
    "\n",
    "        if categories:\n",
    "            cat_dict[cell] = ' '.join(list({k: v for k, v in sorted(categories.items(), key=lambda item: item[1], reverse=True)})[:n_categories])\n",
    "        else:\n",
    "            cat_dict[cell] = None\n",
    "\n",
    "    return cat_dict\n",
    "\n",
    "df = pd.DataFrame()\n",
    "step = .1\n",
    "n_categories = 5\n",
    "\n",
    "for threshold in np.arange(.5,1,step):\n",
    "    cat_dict = get_empath_categories(\n",
    "        probas['GradientBoostingClassifier'],\n",
    "        labels_test,\n",
    "        df_test['aft_comment'].values,\n",
    "        threshold,\n",
    "        .1,\n",
    "        n_categories\n",
    "    )\n",
    "    cat_dict['threshold'] = '{0}'.format(round(threshold,1))\n",
    "    df = df.append(pd.DataFrame([cat_dict]))\n",
    "    \n",
    "word_counts = {'all':Counter()}\n",
    "for _, row in df.iterrows():\n",
    "    for col in df.columns:\n",
    "        if col != 'threshold':\n",
    "            if col not in word_counts:\n",
    "                word_counts[col] = Counter()\n",
    "            if row[col]:\n",
    "                word_counts['all'].update(row[col].split(' '))\n",
    "                word_counts[col].update(row[col].split(' '))\n",
    "                \n",
    "for key in word_counts:\n",
    "    print(key, word_counts[key])\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eastern-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all Counter({'internet': 14, 'communication': 13, 'writing': 11, 'reading': 10, 'journalism': 6, 'negative_emotion': 5, 'speaking': 4, 'messaging': 2, 'help': 2, 'office': 2, 'dance': 2, 'money': 2, 'phone': 2, 'domestic_work': 2, 'family': 2, 'business': 1, 'friends': 1, 'hate': 1, 'wedding': 1, 'social_media': 1, 'computer': 1, 'home': 1, 'shopping': 1, 'sexual': 1, 'swearing_terms': 1, 'ridicule': 1})\n",
      "tp Counter({'internet': 3, 'communication': 3, 'writing': 3, 'journalism': 3, 'reading': 3, 'speaking': 1, 'help': 1, 'office': 1, 'dance': 1, 'money': 1})\n",
      "tn Counter({'communication': 4, 'internet': 4, 'writing': 3, 'negative_emotion': 3, 'reading': 2, 'speaking': 2, 'messaging': 1, 'phone': 1, 'hate': 1, 'domestic_work': 1, 'family': 1, 'home': 1, 'shopping': 1})\n",
      "fp Counter({'internet': 3, 'communication': 3, 'writing': 3, 'reading': 3, 'journalism': 3, 'help': 1, 'office': 1, 'dance': 1, 'money': 1, 'wedding': 1})\n",
      "fn Counter({'internet': 4, 'communication': 3, 'writing': 2, 'reading': 2, 'negative_emotion': 2, 'speaking': 1, 'business': 1, 'friends': 1, 'messaging': 1, 'phone': 1, 'social_media': 1, 'computer': 1, 'sexual': 1, 'domestic_work': 1, 'family': 1, 'swearing_terms': 1, 'ridicule': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>communication internet writing reading speaking</td>\n",
       "      <td>internet communication writing reading journalism</td>\n",
       "      <td>communication internet writing reading speaking</td>\n",
       "      <td>0.5 - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internet writing communication journalism reading</td>\n",
       "      <td>communication internet writing reading speaking</td>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>internet communication writing reading business</td>\n",
       "      <td>0.6 - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internet communication writing journalism reading</td>\n",
       "      <td>internet communication negative_emotion writing messaging</td>\n",
       "      <td>communication internet writing reading journalism</td>\n",
       "      <td>internet communication friends messaging negative_emotion</td>\n",
       "      <td>0.7 - 0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speaking help office dance money</td>\n",
       "      <td>negative_emotion internet communication phone hate</td>\n",
       "      <td>help office dance money wedding</td>\n",
       "      <td>internet negative_emotion phone social_media computer</td>\n",
       "      <td>0.8 - 0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>negative_emotion domestic_work family home shopping</td>\n",
       "      <td>None</td>\n",
       "      <td>sexual domestic_work family swearing_terms ridicule</td>\n",
       "      <td>0.9 - 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tp  \\\n",
       "0  internet communication writing journalism reading   \n",
       "0  internet writing communication journalism reading   \n",
       "0  internet communication writing journalism reading   \n",
       "0                   speaking help office dance money   \n",
       "0                                               None   \n",
       "\n",
       "                                                          tn  \\\n",
       "0            communication internet writing reading speaking   \n",
       "0            communication internet writing reading speaking   \n",
       "0  internet communication negative_emotion writing messaging   \n",
       "0         negative_emotion internet communication phone hate   \n",
       "0        negative_emotion domestic_work family home shopping   \n",
       "\n",
       "                                                  fp  \\\n",
       "0  internet communication writing reading journalism   \n",
       "0  internet communication writing journalism reading   \n",
       "0  communication internet writing reading journalism   \n",
       "0                    help office dance money wedding   \n",
       "0                                               None   \n",
       "\n",
       "                                                          fn  threshold  \n",
       "0            communication internet writing reading speaking  0.5 - 0.6  \n",
       "0            internet communication writing reading business  0.6 - 0.7  \n",
       "0  internet communication friends messaging negative_emotion  0.7 - 0.8  \n",
       "0      internet negative_emotion phone social_media computer  0.8 - 0.9  \n",
       "0        sexual domestic_work family swearing_terms ridicule  0.9 - 1.0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "step = .1\n",
    "\n",
    "for threshold in np.arange(.5,1,step):\n",
    "    cat_dict = get_empath_categories_diff(\n",
    "        probas['GradientBoostingClassifier'],\n",
    "        labels_test,\n",
    "        df_test['aft_comment'].values,\n",
    "        threshold\n",
    "    )\n",
    "    cat_dict['threshold'] = '{0} - {1}'.format(round(threshold,1),round(threshold + step,1))\n",
    "    df = df.append(pd.DataFrame([cat_dict]))\n",
    "    \n",
    "word_counts = {'all':Counter()}\n",
    "for _, row in df.iterrows():\n",
    "    for col in df.columns:\n",
    "        if col != 'threshold':\n",
    "            if col not in word_counts:\n",
    "                word_counts[col] = Counter()\n",
    "            if row[col]:\n",
    "                word_counts['all'].update(row[col].split(' '))\n",
    "                word_counts[col].update(row[col].split(' '))\n",
    "\n",
    "for key in word_counts:\n",
    "    print(key, word_counts[key])\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-navigator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
