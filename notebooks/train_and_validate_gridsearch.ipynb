{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "suburban-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "awful-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "developed-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "    'accuracy':accuracy_score,\n",
    "    'precision':precision_score,\n",
    "    'specificity':partial(precision_score,pos_label = -1),\n",
    "    'recall':recall_score,\n",
    "    'f1':f1_score,\n",
    "    'average_precision':average_precision_score,\n",
    "    'roc_auc':roc_auc_score\n",
    "}\n",
    "\n",
    "def generate_sample(df,n,balance=True):\n",
    "    if balance and n:\n",
    "        pos = df.loc[df['aft_net_sign_helpful'] > 0].sample(int(n/2))\n",
    "        neg = df.loc[df['aft_net_sign_helpful'] < 0].sample(int(n/2))\n",
    "        sample = pos.append(neg)\n",
    "    elif n:\n",
    "        sample = df.loc[df['aft_net_sign_helpful'] != 0].sample(n)\n",
    "    else:\n",
    "        sample = df.loc[df['aft_net_sign_helpful'] != 0]\n",
    "    return sample\n",
    "\n",
    "def proba_to_preds(probability_list,threshold=.5):\n",
    "    preds = []\n",
    "    for proba in probability_list:\n",
    "        if proba[1] > threshold:\n",
    "            preds.append(1)\n",
    "        elif proba[0] > threshold:\n",
    "            preds.append(-1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return preds\n",
    "\n",
    "def results_to_table(proba,truth):\n",
    "    result_dict = results_to_json(proba,truth)\n",
    "    return pd.DataFrame([result_dict])\n",
    "    #return results\n",
    "\n",
    "def results_to_json(proba,truth):\n",
    "    preds = proba_to_preds(proba)\n",
    "    results_dict = {}\n",
    "    for metric in METRICS:\n",
    "        if metric == 'roc_auc':\n",
    "            results_dict[metric] = METRICS[metric](truth,proba[:, 1])\n",
    "        else:\n",
    "            results_dict[metric] = METRICS[metric](truth,preds)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "compatible-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_matrix_path = '/Users/klogg/dev/aft-classification/datasets/vectorized/vectorized_bow_100k_rating_2021-03-30.npz'\n",
    "#feature_path = '/Users/klogg/dev/aft-classification/datasets/vectorized/vectorized_bow_100k_rating_2021-03-30.json'\n",
    "\n",
    "feature_path_w2v = '../datasets/vectorized/vectorized_w2v_rating_2021-03-31.json'\n",
    "\n",
    "def train_and_test_split(feature_path,sparse_matrix_path=None):\n",
    "    with open(feature_path,'r') as filestream:\n",
    "        df = pd.DataFrame(json.load(filestream))\n",
    "\n",
    "    df = generate_sample(df, None)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    if sparse_matrix_path:\n",
    "        with open(sparse_matrix_path,'rb') as filestream:\n",
    "            features = load_npz(filestream)\n",
    "            \n",
    "    else:\n",
    "        features = pd.DataFrame(df['feature_vector'].values.tolist()).to_numpy()\n",
    "\n",
    "    labels = df['aft_net_sign_helpful'].to_numpy()\n",
    "    indicies = np.arange(len(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test, i_train, i_test = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        indicies,\n",
    "        test_size = .2,\n",
    "        stratify = labels,\n",
    "        shuffle = True,\n",
    "        random_state = 1\n",
    "    )\n",
    "    \n",
    "    return features_train, features_test, labels_train, labels_test, i_train, i_test\n",
    "\n",
    "features_train, features_test, labels_train, labels_test, i_train, i_test = train_and_test_split(feature_path_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "addressed-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0\n",
    "\n",
    "def train_and_validate(cls, features_train,labels_train,features_test,labels_test):\n",
    "    cls.fit(\n",
    "        features_train,\n",
    "        labels_train,\n",
    "    )\n",
    "\n",
    "    preds = cls.predict(features_test)\n",
    "    results = results_to_table(preds,labels_test)\n",
    "    return results, preds, cls\n",
    "\n",
    "def get_results_sample(df,preds,i_test,labels_test,n):\n",
    "    result_df = pd.DataFrame({\n",
    "        'i':i_test,\n",
    "        'preds':preds,\n",
    "        'labels':labels_test\n",
    "    })\n",
    "\n",
    "    df = df.merge(result_df,\n",
    "                 how='left',\n",
    "                 left_index=True,\n",
    "                 right_on='i')\n",
    "\n",
    "    false_pos = result_df.loc[(result_df['preds'] == 1) & (result_df['labels'] == -1)]['i'].values\n",
    "    false_neg = result_df.loc[(result_df['preds'] == -1) & (result_df['labels'] == 1)]['i'].values\n",
    "    true_pos = result_df.loc[(result_df['preds'] == 1) & (result_df['labels'] == 1)]['i'].values\n",
    "    true_neg = result_df.loc[(result_df['preds'] == -1) & (result_df['labels'] == -1)]['i'].values\n",
    "    \n",
    "    sample_df = df.iloc[false_pos].sample(n).append(\n",
    "        df.iloc[false_neg].sample(n)).append(\n",
    "        df.iloc[true_pos].sample(n)).append(\n",
    "        df.iloc[true_neg].sample(n))\n",
    "\n",
    "    sample_df = sample_df.sample(frac=1)\n",
    "    return sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "sudden-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'clf__penalty': ['l2'], 'clf__C': [0.1, 1], 'clf': [LogisticRegression()]}, {'clf': [BernoulliNB()]}]\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILEPATH = '../model_config/classifiers.test_params_small.yaml'\n",
    "\n",
    "def class_for_name(class_path):\n",
    "    c = getattr(importlib.import_module(class_path.rsplit('.',1)[0]), class_path.rsplit('.',1)[1])()\n",
    "    return c\n",
    "\n",
    "def format_model_config(yaml):\n",
    "    param_grid = []\n",
    "    for model in yaml:\n",
    "        clf = class_for_name(yaml[model]['class'])\n",
    "        params = {}\n",
    "        for param in yaml[model]['params']:\n",
    "            key = 'clf__{0}'.format(param)\n",
    "            params[key] = yaml[model]['params'][param]\n",
    "        params['clf'] = [clf]\n",
    "        param_grid.append(params)\n",
    "    \n",
    "    return param_grid\n",
    "\n",
    "with open(CONFIG_FILEPATH) as filestream:\n",
    "    model_config = yaml.load(filestream)\n",
    "\n",
    "param_grid = format_model_config(model_config)\n",
    "scoring = ('roc_auc','f1','accuracy','recall','precision')\n",
    "pipe = Pipeline([('clf', DummyEstimator())])\n",
    "\n",
    "print(param_grid)\n",
    "best_models = {}\n",
    "\n",
    "for model in param_grid:\n",
    "    gs = GridSearchCV(pipe, [model], scoring=scoring, n_jobs=32, pre_dispatch=64, refit='roc_auc')\n",
    "    gs.fit(features_train, labels_train)\n",
    "    best_models[str(model['clf'][0].__class__.__name__)] = gs\n",
    "    #cv_results = pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "universal-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "              param_grid=[{'clf': [LogisticRegression(C=0.1)],\n",
       "                           'clf__C': [0.1, 1], 'clf__penalty': ['l2']}],\n",
       "              pre_dispatch=64, refit='roc_auc',\n",
       "              scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision')),\n",
       " 'BernoulliNB': GridSearchCV(estimator=Pipeline(steps=[('clf', DummyEstimator())]), n_jobs=32,\n",
       "              param_grid=[{'clf': [BernoulliNB()]}], pre_dispatch=64,\n",
       "              refit='roc_auc',\n",
       "              scoring=('roc_auc', 'f1', 'accuracy', 'recall', 'precision'))}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "gorgeous-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21036\n",
      "   accuracy  precision  specificity    recall        f1  average_precision  \\\n",
      "0  0.642755   0.595956     0.669042  0.502844  0.545455           0.511595   \n",
      "\n",
      "   roc_auc  \n",
      "0  0.68894  \n",
      "2663\n",
      "   accuracy  precision  specificity    recall        f1  average_precision  \\\n",
      "0  0.855051   0.622642      0.85977  0.082707  0.146018           0.188936   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.576421  \n",
      "21036\n",
      "   accuracy  precision  specificity    recall        f1  average_precision  \\\n",
      "0  0.642755   0.595956     0.669042  0.502844  0.545455           0.511595   \n",
      "\n",
      "   roc_auc  \n",
      "0  0.68894  \n"
     ]
    }
   ],
   "source": [
    "def remove_uncertain_predictions(proba, labels, threshold=.5):\n",
    "    df = pd.DataFrame({\n",
    "        'proba_neg':proba.T[0],\n",
    "        'proba_pos':proba.T[1],\n",
    "        'labels':labels\n",
    "    })\n",
    "    #print(df)\n",
    "    df = df.loc[(df['proba_pos'] > threshold) | ((df['proba_neg'] > threshold))]\n",
    "    return np.vstack([df['proba_neg'].values,df['proba_pos'].values]).T, df['labels'].values, df\n",
    "\n",
    "proba = gs.predict_proba(features_test)\n",
    "t_proba, t_labels, _ = remove_uncertain_predictions(proba,labels_test,.5)\n",
    "print(len(t_proba))\n",
    "print(results_to_table(t_proba,t_labels))\n",
    "t_proba, t_labels, df = remove_uncertain_predictions(proba,labels_test,.8)\n",
    "print(len(t_proba))\n",
    "print(results_to_table(t_proba,t_labels))\n",
    "print(len(labels_test))\n",
    "print(results_to_table(proba,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "following-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264\n",
      "2610\n",
      "399\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(df.loc[df['labels'] == -1]))\n",
    "print(len(df.loc[df['proba_neg'].subtract(df['proba_pos']) > 0]))\n",
    "print(len(df.loc[df['labels'] == 1]))\n",
    "print(len(df.loc[df['proba_neg'].subtract(df['proba_pos']) < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "satisfactory-third",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subject-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_roc_auc</th>\n",
       "      <th>split1_test_roc_auc</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>split4_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844636</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.032518</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>LogisticRegression(C=0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf': LogisticRegression(C=0.1), 'clf__C': 0...</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.685509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584574</td>\n",
       "      <td>0.587385</td>\n",
       "      <td>0.600471</td>\n",
       "      <td>0.587094</td>\n",
       "      <td>0.592099</td>\n",
       "      <td>0.590324</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.062996</td>\n",
       "      <td>0.029165</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>LogisticRegression(C=0.1)</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf': LogisticRegression(C=0.1), 'clf__C': 1...</td>\n",
       "      <td>0.681722</td>\n",
       "      <td>0.685535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.585505</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.586859</td>\n",
       "      <td>0.590598</td>\n",
       "      <td>0.589175</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.844636      0.002922         0.032518        0.000766   \n",
       "1       0.937751      0.062996         0.029165        0.002166   \n",
       "\n",
       "                   param_clf param_clf__C param_clf__penalty  \\\n",
       "0  LogisticRegression(C=0.1)          0.1                 l2   \n",
       "1  LogisticRegression(C=0.1)            1                 l2   \n",
       "\n",
       "                                              params  split0_test_roc_auc  \\\n",
       "0  {'clf': LogisticRegression(C=0.1), 'clf__C': 0...             0.681778   \n",
       "1  {'clf': LogisticRegression(C=0.1), 'clf__C': 1...             0.681722   \n",
       "\n",
       "   split1_test_roc_auc  ...  std_test_recall  rank_test_recall  \\\n",
       "0             0.685509  ...         0.008898                 2   \n",
       "1             0.685535  ...         0.008658                 1   \n",
       "\n",
       "   split0_test_precision  split1_test_precision  split2_test_precision  \\\n",
       "0               0.584574               0.587385               0.600471   \n",
       "1               0.582915               0.585505               0.600000   \n",
       "\n",
       "   split3_test_precision  split4_test_precision  mean_test_precision  \\\n",
       "0               0.587094               0.592099             0.590324   \n",
       "1               0.586859               0.590598             0.589175   \n",
       "\n",
       "   std_test_precision  rank_test_precision  \n",
       "0            0.005626                    1  \n",
       "1            0.005954                    2  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hindu-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "\n",
    "classifier_list = [\n",
    "    LogisticRegression(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter=1000),\n",
    "    GradientBoostingClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=320,\n",
    "        max_features='log2'),\n",
    "    RandomForestClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=100,\n",
    "        max_features='log2'),\n",
    "    SVC(\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "]\n",
    "\n",
    "sample_list = []\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for cls in classifier_list:\n",
    "    results, preds, cls = train_and_validate(\n",
    "        cls,\n",
    "        features_train,\n",
    "        labels_train,\n",
    "        features_test,\n",
    "        labels_test\n",
    "    )\n",
    "    sample = get_results_sample(\n",
    "        df,\n",
    "        preds,\n",
    "        i_test,\n",
    "        labels_test,\n",
    "        n=N\n",
    "    )\n",
    "    results['classifier'] = str(cls.__class__.__name__)\n",
    "    results_df = results_df.append(results)\n",
    "    sample_list.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "attempted-forge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624093</td>\n",
       "      <td>0.593832</td>\n",
       "      <td>0.504628</td>\n",
       "      <td>0.545608</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.624093</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642559</td>\n",
       "      <td>0.608393</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.575759</td>\n",
       "      <td>0.525791</td>\n",
       "      <td>0.642559</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.600647</td>\n",
       "      <td>0.496822</td>\n",
       "      <td>0.543823</td>\n",
       "      <td>0.512904</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.650304</td>\n",
       "      <td>0.611370</td>\n",
       "      <td>0.569644</td>\n",
       "      <td>0.589770</td>\n",
       "      <td>0.531711</td>\n",
       "      <td>0.650304</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   balanced_accuracy  precision    recall        f1  average_precision  \\\n",
       "0           0.624093   0.593832  0.504628  0.545608           0.510826   \n",
       "0           0.642559   0.608393  0.546448  0.575759           0.525791   \n",
       "0           0.625700   0.600647  0.496822  0.543823           0.512904   \n",
       "0           0.650304   0.611370  0.569644  0.589770           0.531711   \n",
       "\n",
       "    roc_auc                  classifier  \n",
       "0  0.624093          LogisticRegression  \n",
       "0  0.642559  GradientBoostingClassifier  \n",
       "0  0.625700      RandomForestClassifier  \n",
       "0  0.650304                         SVC  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-lease",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
